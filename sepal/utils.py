#!/usr/bin/env python3


import re
import datetime

import time as Time
import re
import sys

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib import rcParams

from scipy.spatial import KDTree
from scipy.spatial.distance import cdist
from scipy.ndimage import gaussian_filter

from sklearn.cluster import AgglomerativeClustering as ACl
from sklearn.decomposition import PCA

from typing import Tuple,Dict,Union

from tqdm import tqdm

from joblib import Parallel, delayed
from multiprocessing import cpu_count

import models as m

rcParams.update({'figure.max_open_warning': 0})

def normalize_expression(x : np.ndarray,
                         )->np.ndarray:
    return np.log2(x + 2)


def safe_div(x : Union[np.ndarray,float],
             d : np.ndarray,
             ):
    """ safe division

    Divides x by d (denominator),
    at all instances except for where d = 0
    maintains the original dimensions of x

    Parameters
    ----------
    x : Union[np.ndarray,float]
       vector or number representing nominator
    d : np.ndarray
       vector to divide with, representing the
       denominator

    Returns:
    -------
    vector representing x/d excpet form
    instances where d = 0

    """
    return np.divide(x,
                     d,
                     where = (d.flatten() > 0).reshape(d.shape))

def read_file(pth : str,
              index_col : int = 0,
              )->pd.DataFrame:

    """standard function to read files

    Parameters
    ----------

    pth : str
        path to file
    index_col : int
        column to be used as index

    Returns:
    -------
    Pandas DataFrame with read file

    """

    df = pd.read_csv(pth,
                     sep = '\t',
                     header = 0,
                     engine = 'c',
                     index_col = index_col,
                     )
    return df

def filter_genes(mat pd.DataFrame,
                 min_occur : int = 5,
                 min_expr : int = 0,
                 filter_spurious : bool = True,
                 )->None:

    """filter genes

    will filter a count matrix in place
    expects that the provided matrix has
    genes along columns and observations as
    rows

    mat : pd.DataFrame
        count matrix to be filtered
    min_occur : int
        minimal number of capture locations
        which a gene has to be observed at
    min_expr : minimal total number of
        observed features (taken over all)
        locations for a gene
    filter_spurious: bool
        filter mitochondrial and
        ribosomal genes

    """

    keep_genes = (np.sum(mat.values > 0,
                         axis = 0) > min_occur).astype(int)

    keep_genes *= (np.sum(mat.values,
                          axis = 0) > min_expr).astype(int)

    if filter_spurious:
        keep_genes *= np.array([not bool(re.match('^RP|^MT',x.upper())) \
                                for x in mat.columns]).astype(int)

    mat = mat.iloc[:,keep_genes.astype(bool)]

    return mat


def clean_axes(ax : plt.Axes,
                )->None:
    """cleans axes for aesthetic purposes"""

        ax.set_aspect('equal')
        ax.set_yticks([])
        ax.set_xticks([])
        for pos in ax.spines.keys():
            ax.spines[pos].set_visible(False)

def get_inflection_point(y : np.ndarray,
                         x : np.ndarray = None,
                         sigma : float = 10,
                         )-> Union[int,float]:

    """Finds the inflection point

    Numerically finds the point of
    inflection for a set of observations
    y = f(x). If no x-values are provided
    these are taken as the index of
    the y-values. The function f
    is may be any arbitrary function.

    Parameters:
    ----------
    y : np.ndarray
       function values, y = f(x)
    x : np.ndarray
        independent variable from
        which y is generated by
    sigma : float
        bandwidth of kernel

    Returns:
    -------
    The value x_i s.t. f''(x_i) = 0

    """

    # smpoth observed values
    f_times = gaussian_filter(y,
                              sigma)

    # approximate second derivative
    # and smooth the approximation
    f_d2 = gaussian_filter(np.gradient(np.gradient(f_times)),
                           sigma)

    # ignore the first instances
    # where f'' < 0. To avoid
    # edge effects
    first = np.argmax(f_d2 > 0)
    f_d2[0:first] = 1
    # find point where f''
    # goes below zero
    ipoint = np.argmax(f_d2 <= 0)

    # return x value
    # if provided otherwise
    # index

    if x is not None:
        ipoint = x[ipoint]

    return ipoint

def profiles_profiles(cnt : pd.DataFrame,
                    crd : np.ndarray,
                    rank_values : np.ndarray,
                    ncols : int = 5,
                    side_size : float = 350,
                    qscale : float = None ,
                    normalize : bool = True,
                    pltargs : dict = None,
                    split_title : list = Tuple[str,int],
                    pval : bool = False,
                    ) -> Tuple[plt.Figure,plt.Axes]:

    """Visualize a set of transcription
    profiles.

    it is assumed that rank_values and cnt
    are matched. All values included in
    the expression data will be
    visualized

    Parameters:
    ----------
    cnt : pd.DataFrame
        expression data. Genes as columns
        capture locations as rows.
    crd : np.ndarray
        coordinates to use
    rank_values : np.ndarray
       values by which profiles are ranked. For
       example the diffusion times
    ncols : int
        number of columns to use
    side_size : float
        size of the side of each
        plotted profile. Unit is
        pixels.
    qscale : int
       cutoff for quantile scaling.
       If none provided, no quantile
       scaling is performed.
    normalize : bool
       set to true if log transform
       (normalization) of expression
       values should be performed.
    pltargs : dict
        dictionary with style
        features for plotting
    split_title: Tuple[str,int]
        include if profile names should
        be splitted. First element is string
        to split by, second the element
        to keep.
    pval : bool
        set to True if the rank_values
        correspond to p/q-values.

    Returns
    -------

    Tuple of Figure and the corresponding
    axes objects for the visualized profiles

    """

    # adjust side size to matlab untis
    side_size /= 100

    # get expression values
    ncnt = cnt.values

    # get number of genes
    n_genes = cnt.shape[1]

    # setup figure
    nrows = np.ceil(n_genes / ncols).astype(int)

    figsize = (1.2 * ncols * side_size,
               1.2 * nrows * side_size)

    fig,ax = plt.subplots(nrows,
                          ncols,
                          figsize=figsize)
    ax = ax.flatten()

    # define plot aesthetics
    _pltargs = {'s':40,
                'edgecolor':'black',
                'cmap':plt.cm.magma,
                }


    # set colormap
    use_rgba = False
    if pltargs is not None:
        for k,v in pltargs.items():
            _pltargs[k] = v
            if k == 'cmap':
                # if colormap is given in style dict
                if isinstance(v,str) and v != 'alpha':
                    # try to use specified colormap
                    try:
                        _pltargs[k] = eval("plt.cm." + v)
                    # default to magma if fail
                    except:
                        _pltargs[k] = plt.cm.magma
                # if coloring should be alpha-level
                # based
                else:
                   _pltargs[k] = None
                   use_rgba = True

    for ii in range(n_genes):
        vals = ncnt[:,ii].reshape(-1,)
        if normalize:
            vals = normalize_expression(vals)
        if qscale is not None:
            if qscale > 0 and qscale < 1:
                vals_q = np.quantile(vals,qscale,interpolation = 'nearest')
                vals[vals > vals_q] = vals_q
            else:
                print('WARNING : {} is not a proper quantile value'.format(qscale),
                      'within range (0,1)')

        title = cnt.columns[ii]
        if split_title is not None:
            title = title.split(split_title[0])[int(split_title[1])]


        if pval:
            metric = r"$-log10(p_{val} + \epsilon$)"
        else:
            metric = r"$t_d$"

        ax[ii].set_title('Gene : {} \n'.format(title) + \
                         metric + ': {:0.3f}'.format(rank_values[ii]),
                         fontsize = 15)

        high_ordr = np.argsort(vals)
        if use_rgba:
           rgba = np.zeros((ncnt.shape[0],4))
           rgba[:,2] = 1
           rgba[:,3] = vals[high_ordr]
           mx =  rgba[:,3].max()
           mn = rgba[:,3].min()
           rgba[:,3] = (rgba[:,3] - mn) / (mx-mn)
        else:
           rgba = vals[high_ordr]

        ax[ii].scatter(crd[:,0][high_ordr],
                       crd[:,1][high_ordr],
                       c = rgba,
                       **_pltargs,
                      )
    for ii in range(ncols*nrows):
        clean_axes(ax[ii])


    return (fig,ax)

def get_eigen_dmat(vals : np.ndarray,
                   normalized : bool = True,
                   ) -> np.ndarray :

    n_samples = vals.shape[0]
    dmat = np.zeros((n_samples,n_samples))

    nrm = np.linalg.norm(vals,axis = 1,
                         keepdims = True)
    vals = safe_div(vals,
                     nrm,
                    )

    dmat = np.dot(vals,vals.T)
    dmat[np.abs(dmat - 1) < 10e-6] = 1.0
    dmat[np.abs(dmat + 1) < 10e-6] = -1.0
    dmat = np.arccos(dmat)

    return dmat


def get_eigen( mat : np.ndarray,
               thrs : float = 0.99,
               )-> np.ndarray :

    # mat is n_spots x n_genes
    # Transpose  to treat genes
    # as samples and spots as features
    pca_fit = PCA().fit(mat.T)

    # compute number of components required
    expl_var = pca_fit.explained_variance_ratio_
    n_comps = np.argmax(np.cumsum(expl_var) > thrs)

    # select first n_comps components
    # n_comps x n_spots
    evecs = pca_fit.components_[0:n_comps+1,:]
    # make unit vectors
    norms = np.linalg.norm(evecs,
                            axis = 1,
                            keepdims=True)

    evecs = safe_div(evecs,norms)

    loads = np.dot(evecs,mat).T
    return (evecs,loads)


def cluster_data(counts : np.ndarray,
                 n_base = 500,
                 n_projs = 100,
                 threshold : float = 0.9,
                 ):

    epats,loads = get_eigen(counts[:,0:n_base],
                            thrs = threshold)

    loads = loads[0:n_projs,:]
    norms = np.linalg.norm(loads,
                             axis = 1,
                             keepdims = True,
                             )

    nloads = safe_div(loads,norms)

    n_patterns = epats.shape[0]

    print("[INFO] : Using {} eigenpatterns".format(n_patterns))

    cidx = ACl(n_clusters = n_patterns,
            affinity = 'precomputed',
            linkage = 'complete',
            ).fit_predict(get_eigen_dmat(nloads))

    n_clusters = np.unique(cidx)
    n_clusters = n_clusters[n_clusters >= 0]
    n_clusters = n_clusters.shape[0]

    repr_patterns = {}
    for cl in np.unique(cidx):
        av_loads = np.mean(loads[cidx == cl,:],
                           axis = 0,
                           keepdims = True)

        rpat = np.dot(av_loads,epats).flatten()
        repr_patterns.update({cl:rpat})


    print("[INFO] : Identified {} clusters".format(n_clusters))

    return (cidx,repr_patterns)

def visualize_representative(patterns : Dict[int,np.ndarray],
                             crd : np.ndarray,
                             ncols : int,
                             log : bool = False,
                             side_size : float = 3,
                             pltargs : dict = None,
                             normalize : bool = True,
                             ):

    nrows = np.ceil(len(patterns) / ncols).astype(int)

    _pltargs = {'s':40,
                'edgecolor':'black',
                'cmap':plt.cm.PuRd,
                }

    if pltargs is not None:
        for k,v in pltargs.items():
            _pltargs[k] = v
            if k == 'cmap' and isinstance(k,str):
                _pltargs[k] = eval(v)

    figsize = (1.2 * ncols * side_size,
               1.2 * nrows * side_size)

    fig,ax = plt.subplots(nrows,
                          ncols,
                          figsize = figsize)
    ax = ax.flatten()

    for cl,vals in patterns.items():
        if log:
            vals = normalize_expression(vals)

        ax[cl].scatter(crd[:,0],
                       crd[:,1],
                       c = vals,
                       **_pltargs,
                       )
        ax[cl].set_title("Repr. Pattern {}".format(cl))

    for ii in range(ax.shape[0]):
        ax[ii] = clean_axes(ax[ii])

    return fig,ax


def visualize_clusters(counts : np.ndarray,
                       genes : pd.Index,
                       crd : np.ndarray,
                       labels : np.ndarray,
                       ncols : int,
                       log : bool = True,
                       side_size : float = 3,
                       pltargs : dict = None,
                       normalize : bool = True,
                       split_title : list = None,
                       ):

    _pltargs = {'s':40,
                'edgecolor':'black',
                'cmap':plt.cm.PuRd,
                }

    if pltargs is not None:
        for k,v in pltargs.items():
            _pltargs[k] = v
            if k == 'cmap' and isinstance(k,str):
                _pltargs[k] = eval(v)

    vizlist = []
    uni_labels = np.unique(labels)
    uni_labels = np.sort(uni_labels[uni_labels >= 0])

    for k,lab in enumerate(uni_labels):

        pos = np.where(labels == lab)[0]

        nrows = np.ceil(pos.shape[0] / ncols).astype(int)

        figsize = (1.2 * ncols * side_size,
                   1.2 * nrows * side_size)

        vizlist.append(list(plt.subplots(nrows,
                                         ncols,
                                         figsize = figsize)))

        vizlist[-1][0].suptitle("Family {}".format(lab))

        vizlist[-1][1] = vizlist[-1][1].flatten()

        for ii in range(pos.shape[0]):
            vals = counts[:,pos[ii]]
            if log:
                vals = normalize_expression(vals)

            title = genes[pos[ii]]
            if split_title is not None:
                title = title.split(split_title[0])[int(split_title[1])]

            vizlist[-1][1][ii].set_title("Gene : {}".format(title),
                                         fontsize = 15)
            vizlist[-1][1][ii].scatter(crd[:,0],
                                       crd[:,1],
                                       c = vals,
                                       **_pltargs,
                                       )

            vizlist[-1][1][ii].set_aspect('equal')
            clean_axes(vizlist[-1][1][ii])

        for jj in range(ii+1,ncols*nrows):
            clean_axes(vizlist[-1][1][jj])
            vizlist[-1][1][jj].set_visible(False)

    return vizlist

def timestamp() -> str:
    """generate date-based tag"""
    return re.sub(':|-|\.| |','',
                  str(datetime.datetime.now()))




# def change_crd_index(df : pd.Index,
#                      new_crd : np.ndarray) -> pd.Index :

#     new_idx = [ 'x'.join(crd[x,:].astype(str)) for\
#                 x in range(crd.shape[0])]

#     new_idx = pd.Index(new_idx)

#     old_idx  = df.index
#     df.index = new_idx

#     return (df,old_idx)

